{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5487510-9078-4ab2-9fb6-6a95d71ba24e",
   "metadata": {},
   "source": [
    "# Agenda-based search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dab2a-8369-4477-8a73-0a222b38df8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6513f5-4fa8-4e95-8dac-cbd6816c0b6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, the neighboring stations and their respective zones are obtained using an amended version of the code provided in the assignment:\n",
    "The zone_dict also includes the line of the next station for a given station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2914844-6074-4778-9ee7-5431f4226d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tubedata.csv', header=None)\n",
    "df.head()\n",
    "\n",
    "# Converts the zone from string to integer including outside london zone (Ex: Zone A)\n",
    "\n",
    "def zone_to_int(zone):\n",
    "         \n",
    "    if zone == 'a': zone = 7\n",
    "    elif zone == 'b': zone = 8\n",
    "    elif zone == 'c': zone = 9\n",
    "    elif zone == 'd': zone = 10\n",
    "    else: \n",
    "        try:\n",
    "            zone = int(zone)\n",
    "        except:\n",
    "            print('Unsuported Zone, Zone is None') #Just in case\n",
    "            zone = None\n",
    "    return zone\n",
    "\n",
    "from collections import defaultdict\n",
    " \n",
    "station_dict = defaultdict(list)\n",
    "zone_dict = defaultdict(list)\n",
    "\n",
    "# get data row by row\n",
    "for index, row in df.iterrows():\n",
    "  \n",
    "  start_station = row[0]\n",
    "\n",
    "  end_station = row[1]\n",
    "  act_cost = int(row[3])\n",
    "\n",
    "  line_name = row[2]  \n",
    "    \n",
    "  zone1 = row[4]\n",
    "  zone2 = row[5]\n",
    "\n",
    "  # station dictionary of child station tuples (child_name, cost from parent to the child)\n",
    "  # {\"Mile End\": [(\"Stepney Green\", 2), (\"Wembley\", 1)]}\n",
    "  station_list = station_dict[start_station]\n",
    "  station_list.append((end_station, act_cost,line_name))\n",
    "\n",
    "  # the following two lines add the other direction of the tube \"step\"\n",
    "  station_list = station_dict[end_station]\n",
    "  station_list.append((start_station, act_cost,line_name))\n",
    "  \n",
    "  # we add the main zone\n",
    " # zone_dict[start_station].add(zone1)\n",
    "\n",
    "\n",
    "  zone1 = zone_to_int(zone1)\n",
    "  zone2 = zone_to_int(zone2)\n",
    "  zone_dict[start_station].append(zone1)\n",
    "  # we add the secondary zone\n",
    "  if zone2 != 0:\n",
    "    #zone_dict[start_station].add(zone2)\n",
    "    zone_dict[start_station].append(zone2)\n",
    "    # if the secondary zone is not 0 it's the main zone for the ending station\n",
    "    #zone_dict[end_station].add(zone2)\n",
    "    zone_dict[end_station].append(zone2)\n",
    "  else:\n",
    "    # otherwise the main zone for the ending station is the same as for the starting station\n",
    "    #zone_dict[end_station].add(zone1)\n",
    "    zone_dict[end_station].append(zone1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "604330e9-a2b7-490d-9605-4bc059da8ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Willesden Junction', 3, 'Bakerloo'), (\"Queen's Park\", 3, 'Bakerloo')]\n",
      "[3, 2]\n",
      "End_station is  :  Kensal Green\n"
     ]
    }
   ],
   "source": [
    "## Testing \n",
    "station = 'Kensal Green'\n",
    "print(station_dict[station])\n",
    "print(zone_dict[station])\n",
    "print(\"End_station is  : \" , station )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5d2d5-4c73-43b1-94ec-fd29e8337c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de3e7441-0e85-4e5e-8378-8336a4a22ea7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implementation of DFS, BFS and UCS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0769ee-7f85-4f16-bd6e-0386054448a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Breadth First Search Implementation - **BFS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e34179-d293-4daa-9536-9c8ec1609502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bfs_implementation( origin, destination, counter = 0):\n",
    "  # Add current place to already_visited\n",
    "  next_already_visited = [origin]\n",
    "  # List of existent paths (for now only origin)\n",
    "  total_paths = [[origin]]\n",
    "  \n",
    "  # Will perform exploration of all current paths\n",
    "  while len(total_paths)!= 0:\n",
    "    new_total_paths = []\n",
    "    #Check all paths\n",
    "    for path in total_paths:\n",
    "      # Last element in path, where to go next?\n",
    "      last_element_in_path = path[-1]\n",
    "      counter += 1\n",
    "        \n",
    "      # goal check\n",
    "      if destination in last_element_in_path: return path, counter\n",
    "   \n",
    "      #nodes_found = list( (neighb_stations(graph,last_element_in_path)))\n",
    "      nodes_found = station_dict[last_element_in_path]\n",
    "      if reverse: nodes_found.reverse()\n",
    "      #iterates though neighboring stations:\n",
    "      for node in nodes_found: \n",
    "                \n",
    "        if node[0] not in next_already_visited:  # check if next node has been visited\n",
    "          \n",
    "          next_already_visited.append(node[0])\n",
    "          # Adding possible path for further exploration\n",
    "          new_total_paths = new_total_paths + [path + [node[0]]]     \n",
    "    total_paths = new_total_paths\n",
    "  # If solution does not exist\n",
    "  return [],-1\n",
    "\n",
    "def cost_caulator(path):\n",
    "    path_size = len(path)\n",
    "    total_cost = 0\n",
    "    if path_size < 2:\n",
    "        return 0\n",
    "    for i in range(path_size - 1):\n",
    "        nodes = station_dict[path[i]]\n",
    "        for next_node, cost,line in nodes:\n",
    "            if next_node == path[i+1]:\n",
    "                total_cost+= cost\n",
    "                continue\n",
    "    return total_cost\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f3f21a8-0919-4aeb-8164-83570a66e139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS:\n",
      "bfs_path:  ['Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Stratford']\n",
      "number of explorations = 40\n",
      "Average time (cost) =  15\n"
     ]
    }
   ],
   "source": [
    "print('BFS:')\n",
    "reverse = False # \n",
    "bfs_path, count = bfs_implementation( 'Canada Water', 'Stratford',reverse)\n",
    "print('bfs_path: ', bfs_path)\n",
    "print('number of explorations = {}'.format(count))\n",
    "print('Average time (cost) = ',cost_caulator(bfs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3744fba-34c0-4bd8-b8d7-12628b2e8c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e5aae95-cfb0-4f2a-8220-d003bba951f0",
   "metadata": {},
   "source": [
    "#### Depth First Search Implementation - **DFS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e36fc5b-2cc3-4c1a-a292-e64c543e3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_implementation( start , goal,reverse):\n",
    "    stack = [(start,[])]  # contains explored paths and nodes\n",
    "    explored = []\n",
    "    counts = 0\n",
    "\n",
    "    while stack:\n",
    "       \n",
    "        current_node, current_path = stack.pop() # retrieves last element\n",
    "        counts +=1\n",
    "        \n",
    "        if current_node == goal:\n",
    "            current_path.append(current_node)\n",
    "            cost = cost_caulator(current_path)\n",
    "            return current_path, cost, counts\n",
    "        if current_node not in explored:\n",
    "            explored.append(current_node)\n",
    "            nodes = station_dict[current_node]\n",
    "            if reverse: nodes.reverse()\n",
    "            for n in nodes:\n",
    "                next_node = n[0]\n",
    "                cost = n[1]\n",
    "                stack.append((next_node,current_path +[(current_node)]))\n",
    "    return None, counts\n",
    "\n",
    "def cost_caulator(path):\n",
    "    path_size = len(path)\n",
    "    total_cost = 0\n",
    "    if path_size < 2:\n",
    "        return 0\n",
    "    for i in range(path_size - 1):\n",
    "        nodes = station_dict[path[i]]\n",
    "        for next_node, cost,line in nodes:\n",
    "            if next_node == path[i+1]:\n",
    "                total_cost+= cost\n",
    "                continue\n",
    "    return total_cost\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "995306e4-24d2-412a-99c4-0752f2f043c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS:\n",
      "Path = ['Canada Water', 'Rotherhithe', 'Wapping', 'Shadwell', 'Whitechapel', 'Aldgate East', 'Tower Hill', 'Aldgate', 'Liverpool Street', 'Bethnal Green', 'Mile End', 'Stratford']\n",
      "Average time (cost)  =  28\n",
      "Explored nodes =  616\n"
     ]
    }
   ],
   "source": [
    "print('DFS:')\n",
    "reverse = True\n",
    "path,cost, counts = DFS_implementation( 'Canada Water', 'Stratford',reverse)\n",
    "cost = cost_caulator(path)\n",
    "print('Path =', path)\n",
    "print('Average time (cost)  = ',cost)\n",
    "print('Explored nodes = ',counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "269268c3-209b-4e00-ac50-693e8655bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS:\n",
      "Path = ['Canada Water', 'Rotherhithe', 'Wapping', 'Shadwell', 'Whitechapel', 'Aldgate East', 'Tower Hill', 'Aldgate', 'Liverpool Street', 'Bethnal Green', 'Mile End', 'Stratford']\n",
      "Average time (cost)  =  28\n",
      "Explored nodes =  616\n"
     ]
    }
   ],
   "source": [
    "print('DFS:')\n",
    "reverse = False\n",
    "path,cost, counts = DFS_implementation( 'Canada Water', 'Stratford',reverse)\n",
    "cost = cost_caulator(path)\n",
    "print('Path =', path)\n",
    "print('Average time (cost)  = ',cost)\n",
    "print('Explored nodes = ',counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9466f-1a61-4a3a-994b-93ec83fa4107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12774fe-8867-4495-b8f9-e1bd7d2c659f",
   "metadata": {},
   "source": [
    "#### Uniform Cost Search - **UCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a24478d-5dcb-4c53-b0c7-8e59ec578cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "def UCS_implementation(origin, goal,extended,reverse = False):\n",
    "\n",
    "    #Similar to BFS but has a priority queue\n",
    "    paths_to_explore = PriorityQueue()\n",
    "    visited_nodes = []\n",
    "\n",
    "    #For UCS, the costs and line are added to the queue\n",
    "    paths_to_explore.put(( 0,[origin],None)) #For UCS, the costs ans line are added to the queue\n",
    "    # None is the beginning line for the first station\n",
    "    nodes_explored = 0\n",
    "    while (paths_to_explore.empty()==False):\n",
    "        nodes_explored +=1\n",
    "        actual_cost, path, current_line = paths_to_explore.get() \n",
    "        \n",
    "        current_node = path[-1]\n",
    "        \n",
    "        \n",
    "        visited_nodes.append(current_node)    \n",
    "        \n",
    "        if current_node == goal: \n",
    "            print('Nodes opened = ', nodes_explored )\n",
    "           \n",
    "            return path , actual_cost\n",
    "       \n",
    "        neighbours = station_dict[current_node]\n",
    "        \n",
    "        for nodes in neighbours:\n",
    "            \n",
    "            next_node = nodes[0]\n",
    "            #cost of next node is nodes[1]\n",
    "            new_line = nodes[2]\n",
    "           \n",
    "            cost_node = cost_calculator(actual_cost, nodes[1], current_line, new_line, extended)\n",
    "\n",
    "            #cost_node = nodes[1] + actual_cost ## For non extended only\n",
    "             \n",
    "            new_path = path.copy()\n",
    "\n",
    "            new_path.append(next_node)\n",
    "           \n",
    "           \n",
    "            if next_node not in visited_nodes: paths_to_explore.put((cost_node, new_path,new_line))\n",
    "\n",
    "def cost_calculator(initial_cost, cost_to_be_added, current_line, new_line, ucs_extended):\n",
    "    if (ucs_extended == False or current_line == None or current_line == new_line ): return initial_cost+cost_to_be_added\n",
    "    if current_line != new_line: return initial_cost+cost_to_be_added + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd4e067-9d41-4da8-8213-c9f68cb7822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes opened =  224\n",
      "path =  ['Canada Water', 'Rotherhithe', 'Wapping', 'Shadwell', 'Whitechapel', 'Stepney Green', 'Mile End', 'Stratford']\n",
      "Average_time (cost)  =  14\n"
     ]
    }
   ],
   "source": [
    "extended = False\n",
    "\n",
    "UCS_path, cost = UCS_implementation( 'Canada Water', 'Stratford', extended,reverse)\n",
    "print('path = ', UCS_path)\n",
    "print('Average_time (cost)  = ',cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "373c140d-0c7c-433d-b38c-719021604e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes opened =  69\n",
      "['Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Stratford']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "extended = True\n",
    "\n",
    "bfs_path, cost = UCS_implementation( 'Canada Water', 'Stratford', extended, reverse)\n",
    "print(bfs_path)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f0582-5922-4040-8879-799de4f43c78",
   "metadata": {},
   "source": [
    "## Heuristic Based Search - Best First Seach **BSF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd926465-2964-4ac8-9809-ef0a85914593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def BFS_heuristic_implementation( origin, goal):\n",
    "\n",
    "    paths_to_explore = PriorityQueue()\n",
    "    visited_nodes = []\n",
    "    paths_to_explore.put((0, 0,[origin]))  \n",
    "    #First value, 0 is the heuristic cost\n",
    "    #Second value, 0 is true cost- average time\n",
    "    \n",
    "    nodes_explored = 0\n",
    "    #target_zone = get_zones(graph, goal )[1]\n",
    "    target_zone = zone_dict[goal][1]\n",
    "\n",
    "    print(\"Starting zone = \", zone_dict[origin][0] )\n",
    "    print(\"Target zone = \", target_zone)\n",
    "    \n",
    "    while (paths_to_explore.empty()==False):\n",
    "        \n",
    "        h_cost,actual_cost, path = paths_to_explore.get()\n",
    "        current_node = path[-1]\n",
    "        visited_nodes.append(current_node)       \n",
    "        \n",
    "        if current_node == goal:  return path , actual_cost , nodes_explored \n",
    "            \n",
    "        nodes_explored +=1\n",
    "        neighbours = station_dict[current_node]\n",
    "    \n",
    "        for nodes in neighbours:\n",
    "            \n",
    "            next_node = nodes[0]\n",
    "            cost_node =(actual_cost+ nodes[1])     \n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            next_zone = zone_dict[next_node][0]\n",
    "            h_cost = heuristic_calculator( target_zone, next_zone   ) \n",
    "            \n",
    "            if next_node not in visited_nodes: paths_to_explore.put((h_cost,cost_node, new_path))\n",
    "                \n",
    "\n",
    "def heuristic_calculator( target_zone, next_zone   ):\n",
    "\n",
    "    constant = 1\n",
    "    h_cost = constant * (target_zone - next_zone)\n",
    "    if cost < 0: return -1*h_cost\n",
    "    else: return h_cost\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1583c9-0abc-4b9c-afaf-2a9548ebf8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search\n",
      "Starting zone =  2\n",
      "Target zone =  3\n",
      "Nodes opened =  39\n",
      "path =  ['Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Stratford']\n",
      "Average_time (cost)  =  15\n"
     ]
    }
   ],
   "source": [
    "print('Best First Search')\n",
    "bfs_path, cost,nodes_explored = BFS_heuristic_implementation( 'Canada Water', 'Stratford')\n",
    "print('Nodes opened = ', nodes_explored )\n",
    "print('path = ',bfs_path)\n",
    "print('Average_time (cost)  = ',cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea0c038a-5da0-4738-831c-293166889feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search\n",
      "Starting zone =  3\n",
      "Target zone =  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes opened =  2836\n",
      "path =  ['East Acton', 'White City', \"Shepherd's Bush\", 'Holland Park', 'Notting Hill Gate', 'Queensway', 'Lancaster Gate', 'Marble Arch', 'Bond Street', 'Green Park', 'Westminster', 'Waterloo', 'Southwark', 'London Bridge', 'Bermondsey', 'Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Bromley-by-Bow', 'Bow Road', 'Mile End']\n",
      "Average_time (cost)  =  49\n"
     ]
    }
   ],
   "source": [
    "print('Best First Search')\n",
    "bfs_path, cost,nodes_explored = BFS_heuristic_implementation( 'East Acton', 'Mile End')\n",
    "print('Nodes opened = ', nodes_explored )\n",
    "print('path = ',bfs_path)\n",
    "print('Average_time (cost)  = ',cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923de8e2-71fe-47c2-8c53-062bf02c013e",
   "metadata": {},
   "source": [
    "## Heuristic Based Search - A-Star (A*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e077f69-fc00-48e7-86ba-48dfe858b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from queue import PriorityQueue\n",
    "\n",
    "def a_star_implementation( origin, goal):\n",
    "\n",
    "    paths_to_explore = PriorityQueue()\n",
    "    visited_nodes = []\n",
    "    paths_to_explore.put((0, 0,[origin],None))\n",
    "    #First value, 0 is the heuristic cost\n",
    "    #Second value, 0 is true cost- average time\n",
    "    \n",
    "    nodes_explored = 0\n",
    "    #target_zone = get_zones(graph, goal )[1]\n",
    "    target_zone = zone_dict[goal][1]\n",
    "\n",
    "    print(\"Starting zone = \", zone_dict[origin][0] )\n",
    "    print(\"Target zone = \", target_zone)\n",
    "    \n",
    "    while (paths_to_explore.empty()==False):\n",
    "\n",
    "        #actual_cost, path, current_line = paths_to_explore.get()\n",
    "        h_cost,actual_cost, path,current_line = paths_to_explore.get()\n",
    "        current_node = path[-1]\n",
    "        visited_nodes.append(current_node)       \n",
    "        \n",
    "        if current_node == goal:  return path , actual_cost , nodes_explored \n",
    "            \n",
    "        nodes_explored +=1\n",
    "        neighbours = station_dict[current_node]\n",
    "    \n",
    "        for nodes in neighbours:\n",
    "            \n",
    "            next_node = nodes[0]\n",
    "            new_line = nodes[2]\n",
    "            cost_node =(actual_cost+ nodes[1])     \n",
    "            new_path = path.copy()\n",
    "            new_path.append(next_node)\n",
    "            next_zone = zone_dict[next_node][0]\n",
    "            h_cost = heuristic_calculator( target_zone, next_zone   ) \n",
    "            g_cost = cost_calculator(actual_cost, nodes[1], current_line, new_line, extended)\n",
    "            total_cost = h_cost + g_cost\n",
    "            if next_node not in visited_nodes: paths_to_explore.put((total_cost,cost_node, new_path,new_line))\n",
    "                \n",
    "\n",
    "def heuristic_calculator( target_zone, next_zone   ):\n",
    "\n",
    "    constant = 1\n",
    "    h_cost = constant * (target_zone - next_zone)\n",
    "    if cost < 0: return -1*h_cost\n",
    "    else: return h_cost\n",
    "    \n",
    "def cost_calculator(initial_cost, cost_to_be_added, current_line, new_line, ucs_extended):\n",
    "    if (ucs_extended == False or current_line == None or current_line == new_line ): return initial_cost+cost_to_be_added\n",
    "    if current_line != new_line: return initial_cost+cost_to_be_added + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a98a73-9042-419d-9191-e66bec6db4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0a8a754-99a9-4a40-9406-642959c6b4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Search\n",
      "Starting zone =  2\n",
      "Target zone =  3\n",
      "Nodes opened =  104\n",
      "path =  ['Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Stratford']\n",
      "Average_time (cost)  =  15\n"
     ]
    }
   ],
   "source": [
    "print('A* Search')\n",
    "a_star_path, cost,nodes_explored = a_star_implementation( 'Canada Water', 'Stratford')\n",
    "print('Nodes opened = ', nodes_explored )\n",
    "print('path = ',a_star_path)\n",
    "print('Average_time (cost)  = ',cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab10ac97-f8a6-46c0-8a69-4920a2b0e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Search\n",
      "Starting zone =  3\n",
      "Target zone =  2\n",
      "Nodes opened =  2836\n",
      "path =  ['East Acton', 'White City', \"Shepherd's Bush\", 'Holland Park', 'Notting Hill Gate', 'Queensway', 'Lancaster Gate', 'Marble Arch', 'Bond Street', 'Green Park', 'Westminster', 'Waterloo', 'Southwark', 'London Bridge', 'Bermondsey', 'Canada Water', 'Canary Wharf', 'North Greenwich', 'Canning Town', 'West Ham', 'Bromley-by-Bow', 'Bow Road', 'Mile End']\n",
      "Average_time (cost)  =  49\n"
     ]
    }
   ],
   "source": [
    "print('A* Search')\n",
    "a_star_path, cost,nodes_explored = BFS_heuristic_implementation( 'East Acton', 'Mile End')\n",
    "print('Nodes opened = ', nodes_explored )\n",
    "print('path = ',a_star_path)\n",
    "print('Average_time (cost)  = ',cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e187953-db5c-431e-8a84-72072a2273f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77e8b5-b036-46f6-ad88-09b430bffbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f306e-d798-4ce5-89cd-392d0dcf584f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62a7127d-a187-40f6-a5dd-de5bd13547de",
   "metadata": {},
   "source": [
    "#  Genetic algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0462d0dd-613d-4d99-8d15-63c65b73878d",
   "metadata": {},
   "source": [
    "The following cell is about password generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb8ee4c9-55d3-4cbf-8572-79f548bc59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, operator, time, itertools, math, copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77752fb8-bfc8-43f2-9fa5-28e9ec85932c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3Q520P12R\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2Q4HHHHOTJ': 0.3031195549479525, '2HHZQYUOTJ': 0.2997182297537069}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import hashlib\n",
    "import string\n",
    "\n",
    "def get_password(student_username, l=10):\n",
    "    # Possible characters include upper-case English letters, numbers between 0 and 9 (inclusive), \n",
    "    # and the underscore symbol\n",
    "    options = string.digits + string.ascii_uppercase  + \"_\"\n",
    "\n",
    "    h = hashlib.sha256((\"ECS759P-AI\"+student_username).encode(\"utf-8\"))\n",
    "    d = h.digest()\n",
    "    s = \"\"\n",
    "    for n in d:\n",
    "      s += options[n%len(options)]\n",
    "\n",
    "    return s[0:l]\n",
    "\n",
    "# TO DO: replace *** with your EECS username and uncomment the code\n",
    "student_password = get_password('ec23832')\n",
    "print(student_password)\n",
    "\n",
    "# Distance function\n",
    "def distance_function(string_one, string_two):\n",
    "    score = 0\n",
    "    for i, j in zip(string_one, string_two):\n",
    "        # Square of the absolute difference between two Unicode codes\n",
    "        score += math.sqrt(abs(ord(i) - ord(j)))\n",
    "    return score\n",
    "\n",
    "\n",
    "# Upper bound of the distance value\n",
    "MAX_VALUE = distance_function('0000000000', '__________')\n",
    "\n",
    "# Compute normalised fitness for a list of candidate passwords \n",
    "def get_normalised_fitness(list_of_phrases, student_password):\n",
    "    ordered_dict = dict()\n",
    "    phrase_to_find = student_password\n",
    "    for phrase in list_of_phrases:\n",
    "        # Return 1 when a candidate matches the true password (string distance between them is zero)\n",
    "        ordered_dict[phrase] = 1 - distance_function(phrase, phrase_to_find) / MAX_VALUE\n",
    "    return ordered_dict\n",
    "\n",
    "# Example of how to get fitness values for a list of candidates\n",
    "get_normalised_fitness(['2Q4HHHHOTJ', '2HHZQYUOTJ'], student_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550781ba-0c01-4c98-bbd3-c3cb9e4a81e4",
   "metadata": {},
   "source": [
    "The following cell is about random password and initial population generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "214ae71c-58e2-439a-bc74-e959c6d23b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "password_len = 10\n",
    "\n",
    "pool = []\n",
    "\n",
    "# The function rand_password() creates a random password of the samesize of the original password\n",
    "def rand_password():\n",
    "    pool = \"01234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"\n",
    "    password_len = 10\n",
    "    rand_password = ''\n",
    "    for i in range(password_len):\n",
    "        index = random.randrange(0, len(pool))\n",
    "    \n",
    "        rand_password += pool[index] \n",
    "        #rand_password.append(pool[index])\n",
    "    return rand_password\n",
    "\n",
    "# This functions creates a list of random passwords generated of a given population size\n",
    "def create_init_population(pop_size):\n",
    "    '''\n",
    "    Method to create initial population\n",
    "    '''\n",
    "    population = []\n",
    "\n",
    "    for i in range(0, pop_size):\n",
    "        population.append(rand_password())\n",
    "        \n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a3cbd-5c1f-4aca-a05b-fc4a0857a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "008b31b5-1aaf-48f0-b5e3-583861a7a2eb",
   "metadata": {},
   "source": [
    "Mutation and crossover functions declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b466fd80-b674-4c04-bb77-bda15a90bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(pool_to_mutate, pMuta = 0.5):\n",
    " \n",
    "  # Mutate provided individuals with pMuta probability\n",
    " \n",
    "  mutated_pool = [] #list to save the mutated and non mutated 'password'\n",
    "  for index, indiv in enumerate(pool_to_mutate):\n",
    "    indiv = list(indiv) # convert indiv from str to list  'str' object does not support item assignment\n",
    "    for pos in range(len(indiv)):  #pos is a char in the password\n",
    "      if np.random.rand() <= pMuta:\n",
    "        # pick a random position to swap with\n",
    "        pos2 = random.sample(range(len(indiv)), 1)[0]\n",
    "        # swap the positions\n",
    "        temp_char = indiv[pos]\n",
    "        indiv[pos] = indiv[pos2]\n",
    "        indiv[pos2] = temp_char\n",
    "    indiv = ''.join(indiv) # convert indiv back to str\n",
    "    mutated_pool.append(indiv)\n",
    "  return mutated_pool\n",
    "\n",
    "\n",
    "def crossing_over(pool_to_cross, pCO = 0.1,reproduction = 0):\n",
    " \n",
    "  # Applies crossing over on the selected individuals with a probability pCO\n",
    "   \n",
    "  for index, indiv in enumerate(pool_to_cross):\n",
    "    indiv_ls = list(indiv)  # convert indiv from str to list  'str' object does not support item assignment\n",
    " \n",
    "    if np.random.rand() <= pCO:\n",
    "      # We get the list of all the other selected individuals\n",
    "      others = pool_to_cross[:]\n",
    "\n",
    "      others.remove(indiv)\n",
    "      # We pick randomly one of them\n",
    "      other = others[np.random.choice(len(others))]\n",
    "      # We get its index in order to modify it directly\n",
    "      otherIdx = pool_to_cross.index(other)\n",
    "      # Randomly choose a starting point and\n",
    "      # then we swap the genome starting from that position\n",
    "      # between the two individuals\n",
    "      startingIdx = np.random.choice(len(indiv))\n",
    "      tempChange = indiv[startingIdx:]\n",
    "\n",
    "      # we check if the permutation property is preserved\n",
    "      # (i.e., cities will not be repeated after cross-over)\n",
    "      if not any(character in indiv[:startingIdx] for character in other[startingIdx:]):\n",
    "        indiv = list(indiv)\n",
    "        other = list(other)\n",
    "        indiv[startingIdx:] = other[startingIdx:]\n",
    "        other[startingIdx:] = tempChange\n",
    "        # Modification of the new one\n",
    "        indiv = ''.join(indiv)\n",
    "        other = ''.join(other)  \n",
    "        pool_to_cross[otherIdx] = other\n",
    "        \n",
    "        pool_to_cross[index] = indiv\n",
    "        reproduction+=1\n",
    "    \n",
    "  return pool_to_cross, reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e81f5c2a-1bd9-4d14-a5dc-feb450448c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function sort the fitness and returns the sorted_population as a list\n",
    "# It also returns the best population and its repective fitness\n",
    "def sort_individuals(fitness):\n",
    "  fitness = sorted(fitness.items(), key=lambda x:1-x[1]) # sorted it in a list\n",
    "  best_fitness = fitness[0]\n",
    "  sorted_population = []\n",
    "  for i in fitness: sorted_population.append(i[0])\n",
    "    \n",
    "  return sorted_population , best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f38bf-e829-498e-ad21-3aff401ea4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d730d4cf-99e2-4a69-ae6a-b4d7c9dfd319",
   "metadata": {},
   "source": [
    "## The Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27de15ce-079a-4138-8832-6a846b6b1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best initial population is  UFWP19N05P  and has a fitness of  0.6708553689384302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UFWP19N05P', 0.6708553689384302)\n",
      "('U3K3613000', 0.6864772976128084)\n",
      "('M2Q7Q7A04P', 0.6888825217948757)\n",
      "('W6QM10707G', 0.7055901407312773)\n",
      "('W6QM10707G', 0.7055901407312773)\n",
      "('Q7Q07DP12E', 0.7551526128229828)\n",
      "('U2MA10Q75V', 0.7717848538551728)\n",
      "('U2MA10Q75V', 0.7717848538551728)\n",
      "('V3R139_07P', 0.7735699099372332)\n",
      "('V3R139_07P', 0.7735699099372332)\n",
      "('B3Q631K07X', 0.7754589087396289)\n",
      "('U2M4A0P77Q', 0.7876418531114632)\n",
      "('S1Q473O00Q', 0.8172516346338272)\n",
      "('S1Q473O00Q', 0.8172516346338272)\n",
      "('S1Q473O00Q', 0.8172516346338272)\n",
      "('X2R770Q43P', 0.8218877673406468)\n",
      "('X2R770Q43P', 0.8218877673406468)\n",
      "('X2R770Q43P', 0.8218877673406468)\n",
      "('X2R770Q43P', 0.8218877673406468)\n",
      "('V4N200L40Q', 0.8246034806545037)\n",
      "('B3K630Q12S', 0.8406917160449732)\n",
      "('B3K630Q12S', 0.8406917160449732)\n",
      "('B3K630Q12S', 0.8406917160449732)\n",
      "('V2Q014P23R', 0.8798646014485911)\n",
      "('V2Q014P23R', 0.8798646014485911)\n",
      "('V2Q014P23R', 0.8798646014485911)\n",
      "('V3Q124P20R', 0.9064390793258769)\n",
      "('V3Q124P20R', 0.9064390793258769)\n",
      "('V3Q124P20R', 0.9064390793258769)\n",
      "('V2Q024P13R', 0.9090375997481701)\n",
      "('V2Q024P13R', 0.9090375997481701)\n",
      "('V2Q024P13R', 0.9090375997481701)\n",
      "('V2Q024P13R', 0.9090375997481701)\n",
      "('V3Q610Q23S', 0.9124810051012633)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V0Q342P12R', 0.9128501675924768)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V4Q621P00R', 0.9210255784756664)\n",
      "('V3Q201P12Q', 0.9249340191432497)\n",
      "('V3Q201P12Q', 0.9249340191432497)\n",
      "('V3Q201P12Q', 0.9249340191432497)\n",
      "('V3Q201P12Q', 0.9249340191432497)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V3Q220P14R', 0.9541070174428286)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V2Q620P12R', 0.9708270017004211)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "('V3Q420P12R', 0.9854135008502105)\n",
      "Epochs =  400\n",
      "Reproduction =  23373\n",
      "Best result is  V3Q420P12R  and has a fitness of  0.9854135008502105\n"
     ]
    }
   ],
   "source": [
    "# The genetic algorithm\n",
    "\n",
    "\n",
    "pool = \"01234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"\n",
    "# Population size\n",
    "pop_size = 300\n",
    "half = int(pop_size // 2)\n",
    "# Mutation rate (per gene)\n",
    "\n",
    "reproduction = 0\n",
    "\n",
    "pMuta = 0.3\n",
    "# Crossover rate\n",
    "pCO = 0.8\n",
    "# Maximum Number of generations\n",
    "n_gen = 400\n",
    "\n",
    "# initializing the population\n",
    "population = create_init_population(pop_size)\n",
    "#getting the fitness\n",
    "fitness = get_normalised_fitness(population, student_password)\n",
    "# arranging the population with highest fitness as starting position\n",
    "population, best_fitness = sort_individuals(fitness)\n",
    "\n",
    "\n",
    "print(\"Best initial population is \", best_fitness[0], \" and has a fitness of \", best_fitness[1] )\n",
    "\n",
    "for i in range(n_gen):\n",
    "\n",
    "  # the mating pool is the top halved of the population\n",
    "  # the bottom halved (least fitness) are eliminated; survival of fitness\n",
    "  mating_pool = copy.deepcopy(population)[:half]\n",
    "    \n",
    "  # perform cross over and mutation over the best parents\n",
    "  mating_pool,reproduction = crossing_over(mating_pool, pCO,reproduction)\n",
    "  mating_pool = mutation(mating_pool, pMuta)\n",
    "    \n",
    "  # combine the best of parents and offsprings to form a new population\n",
    "  population = copy.deepcopy(population)[:half] + mating_pool\n",
    "    \n",
    "  # Sort population according to fitness \n",
    "  fitness = get_normalised_fitness(population, student_password)\n",
    "  population, best_fitness = sort_individuals(fitness)\n",
    "  print(best_fitness)\n",
    "  if best_fitness[1] == float(1.0):\n",
    "      break\n",
    "print('Epochs = ',i+1)\n",
    "print('Reproduction = ', reproduction)\n",
    "print(\"Best result is \", best_fitness[0], \" and has a fitness of \", best_fitness[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237410ba-3b69-4814-aae6-0f9929628409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0669dba8-3846-4dfe-b0fb-c41babf8931e",
   "metadata": {},
   "source": [
    "#### Mean and STD for reproduction and epochs\n",
    "First the Genetic algoritm is written as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cee8b4a-d35a-4a1f-ab6b-b0b319814784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algo(pop_size = 300, pMuta = 0.3, pCO = 0.8 ,n_gen = 400):\n",
    "\n",
    "    pool = \"01234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"\n",
    "    \n",
    "    population = create_init_population(pop_size)\n",
    "    fitness = get_normalised_fitness(population, student_password)\n",
    "    population, best_fitness = sort_individuals(fitness)\n",
    "    reproduction = 0\n",
    "    for i in range(n_gen):\n",
    "      \n",
    "      mating_pool = copy.deepcopy(population)[:half]\n",
    "      mating_pool,reproduction = crossing_over(mating_pool, pCO,reproduction)\n",
    "      mating_pool = mutation(mating_pool, pMuta)\n",
    "    \n",
    "      population = copy.deepcopy(population)[:half] + mating_pool\n",
    "        \n",
    "      fitness = get_normalised_fitness(population, student_password)\n",
    "      population, best_fitness = sort_individuals(fitness)\n",
    "     \n",
    "      if best_fitness[1] == float(1.0):\n",
    "          break\n",
    "    return reproduction , i\n",
    "\n",
    "def mean(list_, samples):\n",
    "    mean = 0\n",
    "    for i in range(samples):\n",
    "        mean += list_[i]\n",
    "    return mean / samples\n",
    "def STD(list_,mean,samples):\n",
    "    sum = 0\n",
    "    for i in range(samples):\n",
    "        sum += (list_[i] - mean)**2\n",
    "    return (sum/samples)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf33bd42-ff65-4297-9181-f3b215a6c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples are:  10\n",
      "The mean of reproduction is:  12413.8\n",
      "The standard deviation of reproduction is:  5059.545963819283\n",
      "The mean of epochs is:  208.5\n",
      "The standard deviation of epochs is:  70.75485849042452\n"
     ]
    }
   ],
   "source": [
    "samples = 10\n",
    "reproductions = []\n",
    "l_epochs = []\n",
    "for s in range(samples):\n",
    "    reproductions.append(genetic_algo()[0])\n",
    "    l_epochs.append(genetic_algo()[1])\n",
    "\n",
    "mean_reproduction = mean(reproductions, samples)\n",
    "mean_epochs= mean( l_epochs, samples)\n",
    "std_reproduction = STD(reproductions,mean_reproduction,samples)\n",
    "std_epochs = STD(l_epochs,mean_epochs,samples)\n",
    "print(\"Number of samples are: \",samples)\n",
    "print(\"The mean of reproduction is: \", mean_reproduction)\n",
    "print(\"The standard deviation of reproduction is: \", std_reproduction)\n",
    "print(\"The mean of epochs is: \", mean_epochs)\n",
    "print(\"The standard deviation of epochs is: \", std_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49851a19-1328-4de4-9406-3d8c67176519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf209-9ecf-4392-80de-306769e779f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
